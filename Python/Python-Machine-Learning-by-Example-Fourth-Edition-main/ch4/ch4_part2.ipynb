{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "dac7d1ab",
   "metadata": {},
   "source": [
    "\n",
    "Source codes for Python Machine Learning By Example 4th Edition (Packt Publishing)\n",
    "\n",
    "Chapter 4 Predicting Online Ad Click-Through with Tree-Based Algorithms \n",
    "\n",
    "Author: Yuxi (Hayden) Liu (yuxi.liu.ece@gmail.com)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "72e9660c",
   "metadata": {},
   "source": [
    "# Training on large datasets with online learning "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7579b8d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import timeit\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.preprocessing import OneHotEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d0b84348",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_rows = 100000 * 11\n",
    "df = pd.read_csv(\"train.csv\", nrows=n_rows)\n",
    "\n",
    "X = df.drop(['click', 'id', 'hour', 'device_id', 'device_ip'], axis=1).values\n",
    "Y = df['click'].values\n",
    "\n",
    "n_train = 100000 * 10\n",
    "X_train = X[:n_train]\n",
    "Y_train = Y[:n_train]\n",
    "X_test = X[n_train:]\n",
    "Y_test = Y[n_train:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c82af764",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>OneHotEncoder(handle_unknown=&#x27;ignore&#x27;)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">OneHotEncoder</label><div class=\"sk-toggleable__content\"><pre>OneHotEncoder(handle_unknown=&#x27;ignore&#x27;)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "OneHotEncoder(handle_unknown='ignore')"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "enc = OneHotEncoder(handle_unknown='ignore')\n",
    "enc.fit(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "299f16af",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The number of iterations is set to 1 if using partial_fit.\n",
    "sgd_lr_online = SGDClassifier(loss='log_loss', \n",
    "                              penalty=None, \n",
    "                              fit_intercept=True, \n",
    "                              max_iter=1, \n",
    "                              learning_rate='constant',\n",
    "                              eta0=0.01, \n",
    "                              random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6d2c728e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- 82.425 seconds ---\n"
     ]
    }
   ],
   "source": [
    "start_time = timeit.default_timer()\n",
    "\n",
    "# Use the first 1,000,000 samples for training, and the next 100,000 for testing\n",
    "for i in range(10):\n",
    "    x_train = X_train[i*100000:(i+1)*100000]\n",
    "    y_train = Y_train[i*100000:(i+1)*100000]\n",
    "    x_train_enc = enc.transform(x_train)\n",
    "    sgd_lr_online.partial_fit(x_train_enc.toarray(), y_train, classes=[0, 1])\n",
    "\n",
    "print(f\"--- {(timeit.default_timer() - start_time):.3f} seconds ---\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "83059e42",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training samples: 10000000, AUC on testing set: 0.762\n"
     ]
    }
   ],
   "source": [
    "x_test_enc = enc.transform(X_test)\n",
    "\n",
    "pred = sgd_lr_online.predict_proba(x_test_enc.toarray())[:, 1]\n",
    "print(f'Training samples: {n_train * 10}, AUC on testing set: {roc_auc_score(Y_test, pred):.3f}')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "ae05a899",
   "metadata": {},
   "source": [
    "# Handling multiclass classification "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "192f3a01",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import datasets\n",
    "digits = datasets.load_digits()\n",
    "n_samples = len(digits.images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2caf7e07",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = digits.images.reshape((n_samples, -1))\n",
    "Y = digits.target\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "083cf936",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.2, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e16d7eac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'alpha': 1e-05, 'eta0': 0.01, 'penalty': 'l2'}\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "parameters = {'penalty': ['l2', None],\n",
    "              'alpha': [1e-07, 1e-06, 1e-05, 1e-04],\n",
    "              'eta0': [0.01, 0.1, 1, 10]}\n",
    "\n",
    "sgd_lr = SGDClassifier(loss='log_loss', \n",
    "                       learning_rate='constant', \n",
    "                       fit_intercept=True, \n",
    "                       max_iter=50,\n",
    "                       random_state=42)\n",
    "\n",
    "grid_search = GridSearchCV(sgd_lr, parameters, n_jobs=-1, cv=5)\n",
    "\n",
    "grid_search.fit(X_train, Y_train)\n",
    "print(grid_search.best_params_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "bd6d44ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The accuracy on testing set is: 94.7%\n"
     ]
    }
   ],
   "source": [
    "sgd_lr_best = grid_search.best_estimator_\n",
    "accuracy = sgd_lr_best.score(X_test, Y_test)\n",
    "print(f'The accuracy on testing set is: {accuracy*100:.1f}%')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "70a3abc8",
   "metadata": {},
   "source": [
    "# Implementing logistic regression using TensorFlow "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b1dd54ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "de56cbad",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_rows = 100000\n",
    "df = pd.read_csv(\"train.csv\", nrows=n_rows)\n",
    "\n",
    "X = df.drop(['click', 'id', 'hour', 'device_id', 'device_ip'], axis=1).values\n",
    "Y = df['click'].values\n",
    "\n",
    "n_train = int(n_rows * 0.9)\n",
    "X_train = X[:n_train]\n",
    "Y_train = Y[:n_train] \n",
    "X_test = X[n_train:]\n",
    "Y_test = Y[n_train:] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "678fe91a",
   "metadata": {},
   "outputs": [],
   "source": [
    "enc = OneHotEncoder(handle_unknown='ignore')\n",
    "X_train_enc = enc.fit_transform(X_train).toarray().astype('float32')\n",
    "X_test_enc = enc.transform(X_test).toarray().astype('float32')\n",
    "Y_train = Y_train.astype('float32')\n",
    "Y_test = Y_test.astype('float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "35a4639e",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 1000\n",
    "train_data = tf.data.Dataset.from_tensor_slices((X_train_enc, Y_train))\n",
    "train_data = train_data.repeat().shuffle(5000).batch(batch_size).prefetch(1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "0c2837d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_features = X_train_enc.shape[1]\n",
    "W = tf.Variable(tf.zeros([n_features, 1]))\n",
    "b = tf.Variable(tf.zeros([1]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "4a21684e",
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 0.001\n",
    "optimizer = tf.optimizers.Adam(learning_rate)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "176c1380",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_optimization(x, y):\n",
    "    with tf.GradientTape() as tape:\n",
    "        logits = tf.add(tf.matmul(x, W), b)[:, 0]\n",
    "        loss = tf.reduce_mean(tf.nn.sigmoid_cross_entropy_with_logits(labels=y, logits=logits))\n",
    "    # Update the parameters with respect to the gradient calculations\n",
    "    gradients = tape.gradient(loss, [W, b])\n",
    "    optimizer.apply_gradients(zip(gradients, [W, b]))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "79f98f76",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step: 500, loss: 0.432118\n",
      "step: 1000, loss: 0.425700\n",
      "step: 1500, loss: 0.411149\n",
      "step: 2000, loss: 0.410195\n",
      "step: 2500, loss: 0.398135\n",
      "step: 3000, loss: 0.365835\n",
      "step: 3500, loss: 0.413735\n",
      "step: 4000, loss: 0.425490\n",
      "step: 4500, loss: 0.374507\n",
      "step: 5000, loss: 0.359987\n"
     ]
    }
   ],
   "source": [
    "training_steps = 5000\n",
    "for step, (batch_x, batch_y) in enumerate(train_data.take(training_steps), 1):\n",
    "    run_optimization(batch_x, batch_y)\n",
    "    if step % 500 == 0:\n",
    "        logits = tf.add(tf.matmul(batch_x, W), b)[:, 0]\n",
    "        loss = tf.reduce_mean(tf.nn.sigmoid_cross_entropy_with_logits(labels=batch_y, logits=logits))\n",
    "        print(\"step: %i, loss: %f\" % (step, loss))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "fe3afc7f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUC on testing set: 0.736\n"
     ]
    }
   ],
   "source": [
    "logits = tf.add(tf.matmul(X_test_enc, W), b)[:, 0]\n",
    "pred = tf.nn.sigmoid(logits)\n",
    "auc_metric = tf.keras.metrics.AUC()\n",
    "auc_metric.update_state(Y_test, pred)\n",
    "\n",
    "print(f'AUC on testing set: {auc_metric.result().numpy():.3f}')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "d87fea64",
   "metadata": {},
   "source": [
    "# Feature selection using random forest "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "7043d855",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X\n",
    "Y_train = Y\n",
    "\n",
    "enc = OneHotEncoder(handle_unknown='ignore')\n",
    "X_train_enc = enc.fit_transform(X_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "7407682a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-2 {color: black;background-color: white;}#sk-container-id-2 pre{padding: 0;}#sk-container-id-2 div.sk-toggleable {background-color: white;}#sk-container-id-2 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-2 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-2 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-2 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-2 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-2 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-2 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-2 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-2 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-2 div.sk-item {position: relative;z-index: 1;}#sk-container-id-2 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-2 div.sk-item::before, #sk-container-id-2 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-2 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-2 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-2 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-2 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-2 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-2 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-2 div.sk-label-container {text-align: center;}#sk-container-id-2 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-2 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>RandomForestClassifier(min_samples_split=30, n_jobs=-1, random_state=42)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" checked><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomForestClassifier</label><div class=\"sk-toggleable__content\"><pre>RandomForestClassifier(min_samples_split=30, n_jobs=-1, random_state=42)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "RandomForestClassifier(min_samples_split=30, n_jobs=-1, random_state=42)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Feature selection with random forest\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "random_forest = RandomForestClassifier(n_estimators=100, criterion='gini', min_samples_split=30, n_jobs=-1, random_state=42)\n",
    "random_forest.fit(X_train_enc.toarray(), Y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "e597c593",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1.22776093e-05 1.42544940e-03 8.11601536e-04 ... 7.51812083e-04\n",
      " 8.79340746e-04 8.49537255e-03]\n"
     ]
    }
   ],
   "source": [
    "feature_imp = random_forest.feature_importances_\n",
    "print(feature_imp)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "ed748781",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "10 least important features are:\n",
      " ['x5_f0222e42' 'x8_7d196936' 'x2_ba8f6070' 'x2_300ede9d' 'x5_72c55d0b'\n",
      " 'x2_4390d4c5' 'x5_69e5a5ec' 'x8_023a5294' 'x11_15541' 'x6_2022d54e']\n"
     ]
    }
   ],
   "source": [
    "# bottom 10 weights and the corresponding 10 least important features\n",
    "feature_names = enc.get_feature_names_out()\n",
    "print(np.sort(feature_imp)[:10])\n",
    "bottom_10 = np.argsort(feature_imp)[:10]\n",
    "print('10 least important features are:\\n', feature_names[bottom_10])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "5b65c3f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.00849437 0.00849537 0.00872154 0.01010324 0.0109653  0.01099363\n",
      " 0.01319093 0.01471638 0.01802233 0.01889752]\n",
      "10 most important features are:\n",
      " ['x3_7687a86e' 'x18_157' 'x17_-1' 'x14_1993' 'x8_8a4875bd' 'x2_d9750ee7'\n",
      " 'x3_98572c79' 'x16_1063' 'x15_2' 'x18_33']\n"
     ]
    }
   ],
   "source": [
    "# top 10 weights and the corresponding 10 most important features\n",
    "print(np.sort(feature_imp)[-10:])\n",
    "top_10 = np.argsort(feature_imp)[-10:]\n",
    "print('10 most important features are:\\n', feature_names[top_10])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f701b00",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b30434f",
   "metadata": {},
   "source": [
    "Readers may ignore the next cell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "65ee124d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NbConvertApp] Converting notebook ch4_part2.ipynb to python\n",
      "[NbConvertApp] Writing 5955 bytes to ch4_part2.py\n"
     ]
    }
   ],
   "source": [
    "!jupyter nbconvert --to python ch4_part2.ipynb --TemplateExporter.exclude_input_prompt=True"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
