{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d1d4890d-a136-4be7-88ad-cca747947f4e",
   "metadata": {},
   "source": [
    "Source codes for Python Machine Learning By Example 4th Edition (Packt Publishing)\n",
    "\n",
    "Chapter 12 Making Predictions with Sequences Using Recurrent Neural Networks\n",
    "\n",
    "Author: Yuxi (Hayden) Liu (yuxi.liu.ece@gmail.com)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "851bb88a-6660-4390-9282-bf43e461ac88",
   "metadata": {},
   "source": [
    "# Revisiting stock price forecasting with LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "22828a4c-8789-4f71-9854-987a0629687e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8cfc60ba-9224-4a2c-9bcf-bcee140bae3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reusing the feature generation function we developed\n",
    "def generate_features(df):\n",
    "    \"\"\"\n",
    "    Generate features for a stock/index based on historical price and performance\n",
    "    @param df: dataframe with columns \"Open\", \"Close\", \"High\", \"Low\", \"Volume\", \"Adj Close\"\n",
    "    @return: dataframe, data set with new features\n",
    "    \"\"\"\n",
    "    df_new = pd.DataFrame()\n",
    "    # 6 original features\n",
    "    df_new['open'] = df['Open']\n",
    "    df_new['open_1'] = df['Open'].shift(1)\n",
    "    df_new['close_1'] = df['Close'].shift(1)\n",
    "    df_new['high_1'] = df['High'].shift(1)\n",
    "    df_new['low_1'] = df['Low'].shift(1)\n",
    "    df_new['volume_1'] = df['Volume'].shift(1)\n",
    "    # # 31 generated features\n",
    "    # # average price\n",
    "    df_new['avg_price_5'] = df['Close'].rolling(5).mean().shift(1)\n",
    "    df_new['avg_price_30'] = df['Close'].rolling(21).mean().shift(1)\n",
    "    df_new['avg_price_365'] = df['Close'].rolling(252).mean().shift(1)\n",
    "    df_new['ratio_avg_price_5_30'] = df_new['avg_price_5'] / df_new['avg_price_30']\n",
    "    df_new['ratio_avg_price_5_365'] = df_new['avg_price_5'] / df_new['avg_price_365']\n",
    "    df_new['ratio_avg_price_30_365'] = df_new['avg_price_30'] / df_new['avg_price_365']\n",
    "    # # average volume\n",
    "    df_new['avg_volume_5'] = df['Volume'].rolling(5).mean().shift(1)\n",
    "    df_new['avg_volume_30'] = df['Volume'].rolling(21).mean().shift(1)\n",
    "    df_new['avg_volume_365'] = df['Volume'].rolling(252).mean().shift(1)\n",
    "    df_new['ratio_avg_volume_5_30'] = df_new['avg_volume_5'] / df_new['avg_volume_30']\n",
    "    df_new['ratio_avg_volume_5_365'] = df_new['avg_volume_5'] / df_new['avg_volume_365']\n",
    "    df_new['ratio_avg_volume_30_365'] = df_new['avg_volume_30'] / df_new['avg_volume_365']\n",
    "    # # standard deviation of prices\n",
    "    df_new['std_price_5'] = df['Close'].rolling(5).std().shift(1)\n",
    "    df_new['std_price_30'] = df['Close'].rolling(21).std().shift(1)\n",
    "    df_new['std_price_365'] = df['Close'].rolling(252).std().shift(1)\n",
    "    df_new['ratio_std_price_5_30'] = df_new['std_price_5'] / df_new['std_price_30']\n",
    "    df_new['ratio_std_price_5_365'] = df_new['std_price_5'] / df_new['std_price_365']\n",
    "    df_new['ratio_std_price_30_365'] = df_new['std_price_30'] / df_new['std_price_365']\n",
    "    # # standard deviation of volumes\n",
    "    df_new['std_volume_5'] = df['Volume'].rolling(5).std().shift(1)\n",
    "    df_new['std_volume_30'] = df['Volume'].rolling(21).std().shift(1)\n",
    "    df_new['std_volume_365'] = df['Volume'].rolling(252).std().shift(1)\n",
    "    df_new['ratio_std_volume_5_30'] = df_new['std_volume_5'] / df_new['std_volume_30']\n",
    "    df_new['ratio_std_volume_5_365'] = df_new['std_volume_5'] / df_new['std_volume_365']\n",
    "    df_new['ratio_std_volume_30_365'] = df_new['std_volume_30'] / df_new['std_volume_365']\n",
    "    # # # return\n",
    "    df_new['return_1'] = ((df['Close'] - df['Close'].shift(1)) / df['Close'].shift(1)).shift(1)\n",
    "    df_new['return_5'] = ((df['Close'] - df['Close'].shift(5)) / df['Close'].shift(5)).shift(1)\n",
    "    df_new['return_30'] = ((df['Close'] - df['Close'].shift(21)) / df['Close'].shift(21)).shift(1)\n",
    "    df_new['return_365'] = ((df['Close'] - df['Close'].shift(252)) / df['Close'].shift(252)).shift(1)\n",
    "    df_new['moving_avg_5'] = df_new['return_1'].rolling(5).mean().shift(1)\n",
    "    df_new['moving_avg_30'] = df_new['return_1'].rolling(21).mean().shift(1)\n",
    "    df_new['moving_avg_365'] = df_new['return_1'].rolling(252).mean().shift(1)\n",
    "    # the target\n",
    "    df_new['close'] = df['Close']\n",
    "    df_new = df_new.dropna(axis=0)\n",
    "    return df_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ec9b69f9-82ff-4ac6-a193-29aa84cd4797",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_raw = pd.read_csv('19900101_20230630.csv', index_col='Date')\n",
    "data = generate_features(data_raw)\n",
    "\n",
    "start_train = '1990-01-01'\n",
    "end_train = '2022-12-31'\n",
    "\n",
    "start_test = '2023-01-01'\n",
    "end_test = '2023-06-30'\n",
    "\n",
    "data_train = data.loc[start_train:end_train]\n",
    "X_train = data_train.drop('close', axis=1).values\n",
    "y_train = data_train['close'].values\n",
    "\n",
    "data_test = data.loc[start_test:end_test]\n",
    "X_test = data_test.drop('close', axis=1).values\n",
    "y_test = data_test['close'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "433d14fa-5f4c-4036-8314-541d65cce4a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()\n",
    "\n",
    "X_scaled_train = torch.FloatTensor(scaler.fit_transform(X_train))\n",
    "X_scaled_test = torch.FloatTensor(scaler.transform(X_test))\n",
    "\n",
    "y_train_torch = torch.FloatTensor(y_train)\n",
    "y_test_torch = torch.FloatTensor(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "20dce8e1-2445-44bb-85e0-dbebf16fcbf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a function to create sequences\n",
    "def create_sequences(data, labels, seq_length):\n",
    "    sequences = []\n",
    "    for i in range(len(data) - seq_length):\n",
    "        seq = data[i:i+seq_length]\n",
    "        label = labels[i+seq_length-1]\n",
    "        sequences.append((seq, label))\n",
    "    return sequences\n",
    "\n",
    "    \n",
    "# Create sequences with a sequence length of 5\n",
    "seq_length = 5\n",
    "sequence_train = create_sequences(X_scaled_train, y_train_torch, seq_length)\n",
    "sequence_test = create_sequences(X_scaled_test, y_test_torch, seq_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "619613a7-c1c0-4791-b3de-62ef15fb9089",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "torch.manual_seed(0)\n",
    "\n",
    "batch_size = 128  \n",
    "train_dl = DataLoader(sequence_train, batch_size=batch_size,\n",
    "                      shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "924de558-f9b4-44f3-b3cf-d3248c546954",
   "metadata": {},
   "outputs": [],
   "source": [
    "class RNN(nn.Module):\n",
    "    def __init__(self, input_dim, rnn_hidden_dim, fc_hidden_dim):\n",
    "        super().__init__()\n",
    "        self.rnn = nn.LSTM(input_dim, rnn_hidden_dim, 2,\n",
    "                           batch_first=True)\n",
    "        self.fc1 = nn.Linear(rnn_hidden_dim, fc_hidden_dim)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.fc2 = nn.Linear(fc_hidden_dim, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out, (hidden, cell) = self.rnn(x)\n",
    "        out = hidden[-1, :, :]\n",
    "        out = self.fc1(out)\n",
    "        out = self.relu(out)\n",
    "        out = self.fc2(out)\n",
    "        return out\n",
    "\n",
    "\n",
    "torch.manual_seed(42)\n",
    "rnn_hidden_dim = 16\n",
    "fc_hidden_dim = 16\n",
    "model = RNN(X_train.shape[1], rnn_hidden_dim, fc_hidden_dim) \n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = model.to(device)\n",
    "\n",
    "\n",
    "loss_fn = nn.MSELoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.003)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ae0b5bf5-53cc-4c0f-8989-a615d3031571",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, dataloader, optimizer):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    for seq, label in dataloader:\n",
    "        optimizer.zero_grad()\n",
    "        pred = model(seq.to(device))[:, 0]\n",
    "        loss = loss_fn(pred, label.to(device))\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        total_loss += loss.item()*label.size(0)\n",
    "    return total_loss/len(dataloader.dataset)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a55cecc0-7081-4615-a783-08ba9d5d09de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 - loss: 24797427.9047\n",
      "Epoch 101 - loss: 10503.0117\n",
      "Epoch 201 - loss: 3234.3346\n",
      "Epoch 301 - loss: 2735.4141\n",
      "Epoch 401 - loss: 2297.7157\n",
      "Epoch 501 - loss: 2108.5702\n",
      "Epoch 601 - loss: 1741.5264\n",
      "Epoch 701 - loss: 2798.3159\n",
      "Epoch 801 - loss: 1635.2345\n",
      "Epoch 901 - loss: 1459.4806\n"
     ]
    }
   ],
   "source": [
    "\n",
    "num_epochs = 1000 \n",
    "for epoch in range(num_epochs):\n",
    "    loss = train(model, train_dl, optimizer)\n",
    "    if epoch % 100 == 0:\n",
    "        print(f'Epoch {epoch+1} - loss: {loss:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c25679b2-1f3a-45f8-a945-ac02926a922e",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions, y = [], []\n",
    " \n",
    "for seq, label in sequence_test:\n",
    "    with torch.no_grad():\n",
    "        pred = model.cpu()(seq.view(1, seq_length, X_test.shape[1]))[:, 0]\n",
    "        predictions.append(pred)\n",
    "        y.append(label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "cea9280b-5675-497b-9da0-9d3efb0e13e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R^2: 0.897\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import r2_score\n",
    "print(f'R^2: {r2_score(y, predictions):.3f}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a221aaed-fed8-415d-b291-34ff46884e0b",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f86bbbd2-7c6c-419e-898f-8f683f2600d0",
   "metadata": {},
   "source": [
    "Readers may ignore the next cell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ad91961b-758c-4cdd-8f90-8126bf40ed5c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NbConvertApp] Converting notebook ch12_part2.ipynb to python\n",
      "[NbConvertApp] Writing 7105 bytes to ch12_part2.py\n"
     ]
    }
   ],
   "source": [
    "!jupyter nbconvert --to python ch12_part2.ipynb --TemplateExporter.exclude_input_prompt=True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "609dece8-49c6-489d-8085-29d839097116",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
