{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7b5531ec-f646-4d7e-97b8-ead047c7b3ad",
   "metadata": {},
   "source": [
    "Source codes for Python Machine Learning By Example 4th Edition (Packt Publishing)\n",
    "\n",
    "Chapter 12 Making Predictions with Sequences Using Recurrent Neural Networks\n",
    "\n",
    "Author: Yuxi (Hayden) Liu (yuxi.liu.ece@gmail.com)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9009fbe-9628-4518-9960-ef8eb81d04bd",
   "metadata": {},
   "source": [
    "# Analyzing movie review sentiment with RNNs"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "fc0a4b24-7b74-463d-8cf3-f6e8508fecde",
   "metadata": {},
   "source": [
    "## Analyzing and preprocessing the data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3963bd41-d7ae-4cd8-8c1d-f0d2f5b20a2a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25000 25000\n"
     ]
    }
   ],
   "source": [
    "from torchtext.datasets import IMDB\n",
    "\n",
    "train_dataset = list(IMDB(split='train'))\n",
    "test_dataset = list(IMDB(split='test'))\n",
    "\n",
    "print(len(train_dataset), len(test_dataset))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "64d6a11e-e75f-4ae4-ac54-1d1a8bc5309a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !conda install -c pytorch torchtext -y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "751b0069-1b84-472f-a60d-defe16f33c4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !conda install -c conda-forge portalocker -y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4bc99c63-5c32-4e51-985b-21900ed7cca1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocab-size: 75977\n",
      "Counter({1: 12500, 2: 12500})\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "from collections import Counter, OrderedDict\n",
    "\n",
    "def tokenizer(text):\n",
    "    text = re.sub('<[^>]*>', '', text)\n",
    "    emoticons = re.findall('(?::|;|=)(?:-)?(?:\\)|\\(|D|P)', text.lower())\n",
    "    text = re.sub('[\\W]+', ' ', text.lower()) +\\\n",
    "        ' '.join(emoticons).replace('-', '')\n",
    "    tokenized = text.split()\n",
    "    return tokenized\n",
    "\n",
    "token_counts = Counter()\n",
    "train_labels = []\n",
    "for label, line in train_dataset:\n",
    "    train_labels.append(label)\n",
    "    tokens = tokenizer(line)\n",
    "    token_counts.update(tokens)\n",
    " \n",
    "    \n",
    "print('Vocab-size:', len(token_counts))\n",
    "print(Counter(train_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b763959b-c6f2-40f5-83af-f211fd92cc7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchtext.vocab import vocab\n",
    "\n",
    "sorted_by_freq_tuples = sorted(token_counts.items(), key=lambda x: x[1], reverse=True)\n",
    "ordered_dict = OrderedDict(sorted_by_freq_tuples)\n",
    "\n",
    "vocab_mapping = vocab(ordered_dict)\n",
    "\n",
    "vocab_mapping.insert_token(\"<pad>\", 0)\n",
    "vocab_mapping.insert_token(\"<unk>\", 1)\n",
    "vocab_mapping.set_default_index(1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fa5ca809-98e7-490a-84c3-1804240e3c67",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11, 7, 35, 462]\n",
      "[11, 7, 1]\n"
     ]
    }
   ],
   "source": [
    "print([vocab_mapping[token] for token in ['this', 'is', 'an', 'example']])\n",
    "print([vocab_mapping[token] for token in ['this', 'is', 'example2']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "784cc7c3-6059-4f09-a1e4-845b5595ab39",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "text_transform = lambda x: [vocab[token] for token in tokenizer(x)]    \n",
    "\n",
    "def collate_batch(batch):\n",
    "    label_list, text_list, lengths = [], [], []\n",
    "    for _label, _text in batch:\n",
    "        label_list.append(1. if _label == 2 else 0.)\n",
    "        processed_text = [vocab_mapping[token] for token in tokenizer(_text)]    \n",
    "        text_list.append(torch.tensor(processed_text, dtype=torch.int64))\n",
    "        lengths.append(len(processed_text))\n",
    "    label_list = torch.tensor(label_list)\n",
    "    lengths = torch.tensor(lengths)\n",
    "    padded_text_list = nn.utils.rnn.pad_sequence(\n",
    "        text_list, batch_first=True)\n",
    "    return padded_text_list.to(device), label_list.to(device), lengths.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c639fa2e-a07d-4ee6-8988-7750fb660d13",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from torch.nn.utils.rnn import pad_sequence\n",
    "# a = [torch.tensor([11, 7, 35, 462], dtype=torch.int64), torch.tensor([11, 7, 35, 462, 11], dtype=torch.int64)]\n",
    "# b = [torch.tensor([11, 7, 35], dtype=torch.int64), torch.tensor([11, 7, 35, 462, 11, 12], dtype=torch.int64)]\n",
    "# # c = torch.ones(1, 15, 300)\n",
    "# pad_sequence(a, True).size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4b89d464-12e1-4bb8-94d4-dcfc9c720c6a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[   46,     8,   287,    21,    16,     2,    76,  3987,     3,   226,\n",
      "            10,   381,     2,   461,    14,    65,     9,  1208,    17,     8,\n",
      "            13,   856,     2,   156,    70,   398,    50,    32,  2338,    67,\n",
      "           103,     6,   110,    19,     9,     2,   130,     2,   153,    12,\n",
      "            14,    65,  1002,    14,     4,  1143,   226,     6,  1061,    31,\n",
      "             2,  1317,   293,    10,    61,   542,  1459,    24,     6,   105,\n",
      "            11,   884,    22,   154,     4,  1475,  2472, 13577,    39,    10,\n",
      "           244,     3,    79,   105,   286,    25,     7,   393,     9,    59,\n",
      "            46,     2,   948,  4472,    26,   248,   339,    11,     7,   101,\n",
      "         59776,     4,   333,    55,    76,    18,    16,    11,   272,    12,\n",
      "           283,   694,    87,     6,  2259,   551,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0],\n",
      "        [ 1379,     7,     2,   271,     6,    29,     6,   357,   308,   488,\n",
      "             3,   223,     3,     6,   796, 10115,     9,   115,    15,     7,\n",
      "             2,   419,     9,    11,    20,   409,   883,   239,    33,   796,\n",
      "             9,   115,    19,   141,  1400,     9,    67,    94,     5,  5551,\n",
      "          2642,     2,   353,    63,     2,   388,   223,     5,   715, 74905,\n",
      "         16567,     2,    85,  1095,    34,  1892,  1307,     3,  2823,  6450,\n",
      "            35,   296,     9,  1379,     7,     4,  1990,   630,  2277,  1702,\n",
      "            20,    72,   290,   148,   698,   165,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0],\n",
      "        [   40,     7,    58,   140,     4,   153,    15,   402,   574,  9356,\n",
      "          2433,   687,    12,  3646,  6513,    36,     7,     2,    81,   320,\n",
      "             5,     2,   485,   742,     5,  1234,   533,   151,    21,   122,\n",
      "            12,    25,  1085,    27,  1890,  1177, 12517,    36,    68,  2451,\n",
      "            23,   170,  4327,   149,  2433,  3189,    83,     2,   430,     3,\n",
      "          1638,    31,  2580,     5,  1198,    38,   441,  6513,     3,  1735,\n",
      "            16,    30,    52,   879,  2433,   574,    34,     2,   269,  5091,\n",
      "             7,   522,    34,     2,   185,  2145,  3062,   161,    27,   497,\n",
      "             5,  2234,  2145, 27174,  1026,     8,  2433,     7,     4,   768,\n",
      "           104,    17,    27, 12132,   168,     8,    13,   252,     6,   262,\n",
      "            11,   125,    97,  3325,   100,   813,    19,    25,    97,   255,\n",
      "             3,   176,    30,     5,    96,   795,  3663,     7,     2,    30,\n",
      "             3,    64,   403,     9,     2,   177,    12,    97,  1982,    11,\n",
      "           104,    37,    58,  5301,   585,    11,   173,     7,     4,    55,\n",
      "            50,   462,     5,    87,  2433,   939,   674,  4886,   298,     2,\n",
      "          2725,     3,  1490, 27915,   298,     2,  1345,  5483, 19755,   298,\n",
      "             2,  1345,    13,   314,  9455, 12517,    40,    13,   141,  3317,\n",
      "             9,     2,   137,   199,  2433,     3,    41,    87,    25,   167,\n",
      "             2, 36084,     3,   286,  2134, 24158,   298, 10760,  1051, 45229,\n",
      "            53,   166,  1846,     4,  1562,  1939,    54,    53,  1123,   101,\n",
      "             4,  5944,    39,    53,   126,   127,    10,   138,    78,     4,\n",
      "           334,     5,  2433,   235,  1538,     3,    10,   131,   357,   148,\n",
      "            96,    40,    14,     4,   981,    16,   109,   155,    12,    33,\n",
      "          1163,    21,   790,  2433,   533,    32,    31,    19,   149,    25,\n",
      "            13,   144,   144,    16,    30,    52,   879],\n",
      "        [   80,    24,   437,   129,    57,   148,    11,   884,    22,   182,\n",
      "             6,  2074,     8,    16,    31,     2,   355,   183,    22,  1600,\n",
      "            21,    80,     6,    95,     4,    50,    20,    10,   244,    24,\n",
      "            30,     6,   626,   728,     4,    18,    19,    11,    30,     7,\n",
      "           952,    10,  1043,  3699,    57,    62,    33,   560,   202,   144,\n",
      "            10,   230,  4808,     6,   890,    11,  4457,     6,  3078,   405,\n",
      "            24,     6,   437,    67,    57,   148,    11,   587,    46,    11,\n",
      "            14,     4,  1425,  1160,    10,    61,    28,     6,   133,    24,\n",
      "            76,    19,    64,    16,     2,    84,  1102,  5460,   101,    12,\n",
      "             8,   212,   610,     2,  1941,     2,    76,  3921,     2,    76,\n",
      "           370,     4,    50,   367,   125,    97,    28,    91,     8,    74,\n",
      "           128,     3,   418,  4913,    17,     2,  2902,  1677,   943,    58,\n",
      "           351,    10,    14,  1370,     8,    14,   170,     6,    75,   128,\n",
      "            19,     8,   151,    21,   149,    87,     2,   598,   120,     8,\n",
      "          1003,     4,   463,   238,     7,    52,  1243,    19,   300,    16,\n",
      "          3131,    60,    57,    10,    28,   304,    60,  2449,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0]], device='cuda:0')\n",
      "tensor([0., 1., 1., 0.], device='cuda:0')\n",
      "tensor([106,  76, 247, 158], device='cuda:0')\n",
      "torch.Size([4, 247])\n"
     ]
    }
   ],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "torch.manual_seed(0)\n",
    "dataloader = DataLoader(train_dataset, batch_size=4, shuffle=True, collate_fn=collate_batch)\n",
    "text_batch, label_batch, length_batch = next(iter(dataloader))\n",
    "print(text_batch)\n",
    "print(label_batch)\n",
    "print(length_batch)\n",
    "print(text_batch.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f336331b-f28c-40a4-b3ee-bed29fb44856",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 32  \n",
    "\n",
    "train_dl = DataLoader(train_dataset, batch_size=batch_size,\n",
    "                      shuffle=True, collate_fn=collate_batch)\n",
    "\n",
    "test_dl = DataLoader(test_dataset, batch_size=batch_size,\n",
    "                     shuffle=False, collate_fn=collate_batch)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "6d4aa14a-7b78-45a9-b475-6a719c1452fc",
   "metadata": {},
   "source": [
    "## Building a simple LSTM network "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "fae6200a-1998-43bb-89e7-d0823a9f3a6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_size = len(vocab_mapping)\n",
    "embed_dim = 32\n",
    "rnn_hidden_dim = 50\n",
    "fc_hidden_dim = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f8c616ed-92ef-49a1-b48e-df842fb088fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "class RNN(nn.Module):\n",
    "    def __init__(self, vocab_size, embed_dim, rnn_hidden_dim, fc_hidden_dim):\n",
    "        super().__init__()\n",
    "        self.embedding = nn.Embedding(vocab_size, \n",
    "                                      embed_dim, \n",
    "                                      padding_idx=0) \n",
    "        self.rnn = nn.LSTM(embed_dim, rnn_hidden_dim, \n",
    "                           batch_first=True)\n",
    "        self.fc1 = nn.Linear(rnn_hidden_dim, fc_hidden_dim)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.fc2 = nn.Linear(fc_hidden_dim, 1)\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "\n",
    "    def forward(self, text, lengths):\n",
    "        out = self.embedding(text)\n",
    "        out = nn.utils.rnn.pack_padded_sequence(out, lengths.cpu().numpy(), enforce_sorted=False, batch_first=True)\n",
    "        out, (hidden, cell) = self.rnn(out)\n",
    "        out = hidden[-1, :, :]\n",
    "        out = self.fc1(out)\n",
    "        out = self.relu(out)\n",
    "        out = self.fc2(out)\n",
    "        out = self.sigmoid(out)\n",
    "        return out\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1d401ea2-788e-466d-9ea4-4974e422bfb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = RNN(vocab_size, embed_dim, rnn_hidden_dim, fc_hidden_dim) \n",
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "7b8c82d7-3c75-4b18-bd06-9914b44373d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_fn = nn.BCELoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.003)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c85b1bb9-e7b3-4e3b-9ce3-5e65d58a05a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, dataloader, optimizer):\n",
    "    model.train()\n",
    "    total_acc, total_loss = 0, 0\n",
    "    for text_batch, label_batch, length_batch in dataloader:\n",
    "        optimizer.zero_grad()\n",
    "        pred = model(text_batch, length_batch)[:, 0]\n",
    "        loss = loss_fn(pred, label_batch)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        total_acc += ((pred>=0.5).float() == label_batch).float().sum().item()\n",
    "        total_loss += loss.item()*label_batch.size(0)\n",
    "\n",
    "    total_loss /= len(dataloader.dataset)\n",
    "    total_acc /= len(train_dl.dataset)\n",
    "    print(f'Epoch {epoch+1} - loss: {total_loss:.4f} - accuracy: {total_acc:.4f}')\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "0a271ede-dd93-4912-9d76-68226c53fff9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 - loss: 0.5925 - accuracy: 0.6757\n",
      "Epoch 2 - loss: 0.4371 - accuracy: 0.7940\n",
      "Epoch 3 - loss: 0.3374 - accuracy: 0.8524\n",
      "Epoch 4 - loss: 0.1701 - accuracy: 0.9368\n",
      "Epoch 5 - loss: 0.0897 - accuracy: 0.9706\n",
      "Epoch 6 - loss: 0.0479 - accuracy: 0.9866\n",
      "Epoch 7 - loss: 0.0298 - accuracy: 0.9914\n",
      "Epoch 8 - loss: 0.0226 - accuracy: 0.9934\n",
      "Epoch 9 - loss: 0.0110 - accuracy: 0.9971\n",
      "Epoch 10 - loss: 0.0059 - accuracy: 0.9988\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(0)\n",
    "num_epochs = 10 \n",
    "for epoch in range(num_epochs):\n",
    "    train(model, train_dl, optimizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "2f674cf5-457b-49aa-9521-715a728c85ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on test set: 85.148 %\n"
     ]
    }
   ],
   "source": [
    "def evaluate(model, dataloader):\n",
    "    model.eval()\n",
    "    total_acc = 0\n",
    "    with torch.no_grad():\n",
    "        for text_batch, label_batch, lengths in dataloader:\n",
    "            pred = model(text_batch, lengths)[:, 0]\n",
    "            total_acc += ((pred>=0.5).float() == label_batch).float().sum().item()\n",
    "    print(f'Accuracy on test set: {100 * total_acc/len(dataloader.dataset)} %')\n",
    " \n",
    "evaluate(model, test_dl)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "43642b19-1587-4bbf-beac-3c23164de969",
   "metadata": {},
   "source": [
    "## Stacking multiple LSTM layers "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "bdb06035-aa5f-4543-947c-bb343f7f2cf1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LSTM(32, 50, num_layers=2, batch_first=True)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nn.LSTM(embed_dim, rnn_hidden_dim, num_layers=2, batch_first=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "586d207a-00a7-40a0-854c-7592e6976c63",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93b70a9b-1da8-45a4-8229-44ee1c8f1b0a",
   "metadata": {},
   "source": [
    "Readers may ignore the next cell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "edc6c742-cb05-4d92-9ae3-66f0009af123",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NbConvertApp] Converting notebook ch12_part1.ipynb to python\n",
      "[NbConvertApp] Writing 6022 bytes to ch12_part1.py\n"
     ]
    }
   ],
   "source": [
    "!jupyter nbconvert --to python ch12_part1.ipynb --TemplateExporter.exclude_input_prompt=True"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
