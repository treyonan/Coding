{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1819a6c9",
   "metadata": {},
   "source": [
    "Source codes for Python Machine Learning By Example 4th Edition (Packt Publishing)\n",
    "\n",
    "Chapter 8 Discovering Underlying Topics in the Newsgroups Dataset with Clustering and Topic Modeling\n",
    "\n",
    "Author: Yuxi (Hayden) Liu (yuxi.liu.ece@gmail.com)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fe12ef3",
   "metadata": {},
   "source": [
    "# Clustering newsgroups dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc1569c4",
   "metadata": {},
   "source": [
    "## Clustering newsgroups data using k-means "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f350cdb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import fetch_20newsgroups\n",
    "\n",
    "categories = [\n",
    "    'alt.atheism',\n",
    "    'talk.religion.misc',\n",
    "    'comp.graphics',\n",
    "    'sci.space',\n",
    "]\n",
    "\n",
    "groups = fetch_20newsgroups(subset='all', categories=categories)\n",
    "\n",
    "labels = groups.target\n",
    "label_names = groups.target_names\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8fbbd85d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.corpus import names\n",
    "all_names = set(names.words())\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "def get_cleaned_data(groups, lemmatizer, remove_words):\n",
    "    data_cleaned = []\n",
    "\n",
    "    for doc in groups.data:\n",
    "        doc = doc.lower()\n",
    "        doc_cleaned = ' '.join(lemmatizer.lemmatize(word) for word in doc.split() if word.isalpha() and word not in remove_words)\n",
    "        data_cleaned.append(doc_cleaned)\n",
    "        \n",
    "    return data_cleaned\n",
    "\n",
    "data_cleaned = get_cleaned_data(groups, lemmatizer, all_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "68075e8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "count_vector = CountVectorizer(stop_words=\"english\", max_features=None, max_df=0.5, min_df=2)\n",
    "data_cv = count_vector.fit_transform(data_cleaned)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2de095ec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>KMeans(n_clusters=4, n_init=&#x27;auto&#x27;, random_state=42)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">KMeans</label><div class=\"sk-toggleable__content\"><pre>KMeans(n_clusters=4, n_init=&#x27;auto&#x27;, random_state=42)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "KMeans(n_clusters=4, n_init='auto', random_state=42)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "k = 4\n",
    "kmeans = KMeans(n_clusters=k, n_init='auto', random_state=42)\n",
    "\n",
    "kmeans.fit(data_cv)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "79d32896",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter({3: 3360, 0: 17, 1: 7, 2: 3})\n"
     ]
    }
   ],
   "source": [
    "clusters = kmeans.labels_\n",
    "\n",
    "from collections import Counter\n",
    "print(Counter(clusters))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f0a42a66",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "tfidf_vector = TfidfVectorizer(stop_words='english', max_features=None, max_df=0.5, min_df=2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "28361daa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter({1: 1478, 2: 797, 0: 601, 3: 511})\n"
     ]
    }
   ],
   "source": [
    "data_tv = tfidf_vector.fit_transform(data_cleaned)\n",
    "kmeans.fit(data_tv)\n",
    "clusters = kmeans.labels_\n",
    "print(Counter(clusters))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e2d9f9fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cluster_0: 601 samples\n",
      "- sci.space: 598 samples\n",
      "- alt.atheism: 1 samples\n",
      "- talk.religion.misc: 1 samples\n",
      "- comp.graphics: 1 samples\n",
      "Top 10 terms:\n",
      "just orbit moon hst nasa mission launch wa shuttle space \n",
      "\n",
      "cluster_1: 1478 samples\n",
      "- alt.atheism: 522 samples\n",
      "- talk.religion.misc: 387 samples\n",
      "- sci.space: 338 samples\n",
      "- comp.graphics: 231 samples\n",
      "Top 10 terms:\n",
      "say people know like think ha just university wa article \n",
      "\n",
      "cluster_2: 797 samples\n",
      "- comp.graphics: 740 samples\n",
      "- sci.space: 49 samples\n",
      "- talk.religion.misc: 5 samples\n",
      "- alt.atheism: 3 samples\n",
      "Top 10 terms:\n",
      "computer need know looking thanks university program file graphic image \n",
      "\n",
      "cluster_3: 511 samples\n",
      "- alt.atheism: 273 samples\n",
      "- talk.religion.misc: 235 samples\n",
      "- sci.space: 2 samples\n",
      "- comp.graphics: 1 samples\n",
      "Top 10 terms:\n",
      "doe bible think believe say people christian jesus wa god \n",
      "\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "cluster_label = {i: labels[np.where(clusters == i)] for i in range(k)}\n",
    "\n",
    "terms = tfidf_vector.get_feature_names_out()\n",
    "centroids = kmeans.cluster_centers_\n",
    "for cluster, index_list in cluster_label.items():\n",
    "    counter = Counter(cluster_label[cluster])\n",
    "    print(f'cluster_{cluster}: {len(index_list)} samples')\n",
    "    for label_index, count in sorted(counter.items(), key=lambda x: x[1], reverse=True):\n",
    "        print(f'- {label_names[label_index]}: {count} samples')\n",
    "    print('Top 10 terms:')\n",
    "    for ind in centroids[cluster].argsort()[-10:]:\n",
    "        print('%s ' % terms[ind], end=\"\")\n",
    "    print('\\n')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5471b66e",
   "metadata": {},
   "source": [
    "## Describing the clusters using GPT "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "286ea72c",
   "metadata": {},
   "outputs": [],
   "source": [
    "keywords = ' '.join(terms[ind] for ind in centroids[0].argsort()[-100:])  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "972c799c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "big power vehicle using alaska look mass money marketing company loss pluto russian scheduled office express probably research software funding billboard online pat access doe telescope april jet usa digest light want prize forwarded way large mar project sci center command technology air government commercial good work servicing know going comet world propulsion people idea design data university day international use orbital long science need time sky program thing make spencer new year earth spacecraft flight henry billion rocket think ha station lunar solar like cost satellite article toronto zoology just orbit moon hst nasa mission launch wa shuttle space\n"
     ]
    }
   ],
   "source": [
    "print(keywords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9f9c9009",
   "metadata": {},
   "outputs": [],
   "source": [
    "import openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1f6133de",
   "metadata": {},
   "outputs": [],
   "source": [
    "# openai.api_key = '<YOUR API KEY>'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2e12234c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_completion(prompt, model=\"text-davinci-003\"):\n",
    "    messages = [{\"role\": \"user\", \"content\": prompt}]\n",
    "    response = openai.ChatCompletion.create(\n",
    "        model=model,\n",
    "        messages=messages,\n",
    "        temperature=0\n",
    "    )\n",
    "    return response.choices[0].message[\"content\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "39038184",
   "metadata": {},
   "outputs": [],
   "source": [
    "# response = get_completion(f\"Describe a common topic based on the following keywords: {keywords}\")\n",
    "# print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c96a6f78",
   "metadata": {},
   "source": [
    "# Discovering underlying topics in newsgroups "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d41a594b",
   "metadata": {},
   "source": [
    "## Topic modeling using NMF "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "2c2c609c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import NMF\n",
    "\n",
    "t = 20\n",
    "nmf = NMF(n_components=t, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a787bf09",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.00000000e+00 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "  0.00000000e+00 1.82524532e-04]\n",
      " [0.00000000e+00 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "  7.77697392e-04 3.85995474e-03]\n",
      " [0.00000000e+00 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00]\n",
      " ...\n",
      " [0.00000000e+00 0.00000000e+00 0.00000000e+00 ... 2.71332203e-02\n",
      "  0.00000000e+00 0.00000000e+00]\n",
      " [0.00000000e+00 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "  0.00000000e+00 4.31048632e-05]\n",
      " [0.00000000e+00 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00]]\n"
     ]
    }
   ],
   "source": [
    "nmf.fit(data_cv)\n",
    "\n",
    "print(nmf.components_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f2f92a84",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Topic 0:\n",
      "available quality program free color version gif file image jpeg\n",
      "Topic 1:\n",
      "ha article make know doe say like just people think\n",
      "Topic 2:\n",
      "include available analysis user software ha processing data tool image\n",
      "Topic 3:\n",
      "atmosphere kilometer surface ha earth wa planet moon spacecraft solar\n",
      "Topic 4:\n",
      "communication technology venture service market ha commercial space satellite launch\n",
      "Topic 5:\n",
      "verse wa jesus father mormon shall unto mcconkie lord god\n",
      "Topic 6:\n",
      "format message server object image mail file ray send graphic\n",
      "Topic 7:\n",
      "christian people doe atheism believe religion belief religious god atheist\n",
      "Topic 8:\n",
      "file graphic grass program ha package ftp available image data\n",
      "Topic 9:\n",
      "speed material unified star larson book universe theory physicist physical\n",
      "Topic 10:\n",
      "planetary station program group astronaut center mission shuttle nasa space\n",
      "Topic 11:\n",
      "infrared high astronomical center acronym observatory satellite national telescope space\n",
      "Topic 12:\n",
      "used occurs true form ha ad premise conclusion argument fallacy\n",
      "Topic 13:\n",
      "gospel people day psalm prophecy christian ha matthew wa jesus\n",
      "Topic 14:\n",
      "doe word hanging say greek matthew mr act wa juda\n",
      "Topic 15:\n",
      "siggraph graphic file information format isbn data image ftp available\n",
      "Topic 16:\n",
      "venera mar lunar surface space venus soviet mission wa probe\n",
      "Topic 17:\n",
      "april book like year time people new did article wa\n",
      "Topic 18:\n",
      "site retrieve ftp software data information client database gopher search\n",
      "Topic 19:\n",
      "use look xv color make program correction bit gamma image\n"
     ]
    }
   ],
   "source": [
    "terms_cv = count_vector.get_feature_names_out()\n",
    "for topic_idx, topic in enumerate(nmf.components_):\n",
    "        print(\"Topic {}:\" .format(topic_idx))\n",
    "        print(\" \".join([terms_cv[i] for i in topic.argsort()[-10:]]))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "9775c380",
   "metadata": {},
   "source": [
    "## Topic modeling using LDA "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "260eb2bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import LatentDirichletAllocation\n",
    "\n",
    "t = 20\n",
    "lda = LatentDirichletAllocation(n_components=t, learning_method='batch',random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "75a13f57",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.05      2.05      2.05      ... 0.05      0.05      0.05     ]\n",
      " [0.05      0.05      0.05      ... 0.05      0.05      0.05     ]\n",
      " [0.05      0.05      0.05      ... 4.0336285 0.05      0.05     ]\n",
      " ...\n",
      " [0.05      0.05      0.05      ... 0.05      0.05      0.05     ]\n",
      " [0.05      0.05      0.05      ... 0.05      0.05      0.05     ]\n",
      " [0.05      0.05      0.05      ... 0.05      0.05      3.05     ]]\n"
     ]
    }
   ],
   "source": [
    "lda.fit(data_cv)\n",
    "\n",
    "print(lda.components_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "4dad287c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Topic 0:\n",
      "atheist doe ha believe say jesus people christian wa god\n",
      "Topic 1:\n",
      "moment just adobe want know ha wa hacker article radius\n",
      "Topic 2:\n",
      "center point ha wa available research computer data graphic hst\n",
      "Topic 3:\n",
      "objective argument just thing doe people wa think say article\n",
      "Topic 4:\n",
      "time like brian ha good life want know just wa\n",
      "Topic 5:\n",
      "computer graphic think know need university just article wa like\n",
      "Topic 6:\n",
      "free program color doe use version gif jpeg file image\n",
      "Topic 7:\n",
      "gamma ray did know university ha just like article wa\n",
      "Topic 8:\n",
      "tool ha processing using data software color program bit image\n",
      "Topic 9:\n",
      "apr men know ha think woman just university article wa\n",
      "Topic 10:\n",
      "jpl propulsion mission april mar jet command data spacecraft wa\n",
      "Topic 11:\n",
      "russian like ha university redesign point option article space station\n",
      "Topic 12:\n",
      "ha van book star material physicist universe physical theory wa\n",
      "Topic 13:\n",
      "bank doe book law wa article rushdie muslim islam islamic\n",
      "Topic 14:\n",
      "think gopher routine point polygon book university article know wa\n",
      "Topic 15:\n",
      "ha rocket new lunar mission satellite shuttle nasa launch space\n",
      "Topic 16:\n",
      "want right article ha make like just think people wa\n",
      "Topic 17:\n",
      "just light space henry wa like zoology sky article toronto\n",
      "Topic 18:\n",
      "comet venus solar moon orbit planet earth probe ha wa\n",
      "Topic 19:\n",
      "site format image mail program available ftp send file graphic\n"
     ]
    }
   ],
   "source": [
    "for topic_idx, topic in enumerate(lda.components_):\n",
    "        print(\"Topic {}:\" .format(topic_idx))\n",
    "        print(\" \".join([terms_cv[i] for i in topic.argsort()[-10:]]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11d197ff",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1ab0fef",
   "metadata": {},
   "source": [
    "Readers may ignore the next cell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "6081ccc5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NbConvertApp] Converting notebook ch8_part2.ipynb to python\n",
      "[NbConvertApp] Writing 4498 bytes to ch8_part2.py\n"
     ]
    }
   ],
   "source": [
    "!jupyter nbconvert --to python ch8_part2.ipynb --TemplateExporter.exclude_input_prompt=True"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
