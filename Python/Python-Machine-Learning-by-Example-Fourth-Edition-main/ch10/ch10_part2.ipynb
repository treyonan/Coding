{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "58b6bd80",
   "metadata": {},
   "source": [
    "Source codes for Python Machine Learning By Example 4th Edition (Packt Publishing)\n",
    "\n",
    "Chapter 10 Machine Learning Best Practices\n",
    "\n",
    "Author: Yuxi (Hayden) Liu (yuxi.liu.ece@gmail.com)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a9e3168",
   "metadata": {},
   "source": [
    "## Best practice 14 – Extracting features from text data "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02beb221",
   "metadata": {},
   "source": [
    "### Word embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3d9474cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models import Word2Vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "240dc583",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vector for 'machine': [ 9.2815855e-05  3.0779743e-03 -6.8117767e-03 -1.3753572e-03\n",
      "  7.6693585e-03  7.3465472e-03 -3.6724545e-03  2.6435424e-03\n",
      " -8.3174659e-03  6.2051434e-03 -4.6373457e-03 -3.1652437e-03\n",
      "  9.3113342e-03  8.7273103e-04  7.4911476e-03 -6.0739564e-03\n",
      "  5.1591368e-03  9.9220201e-03 -8.4587047e-03 -5.1362212e-03\n",
      " -7.0644980e-03 -4.8613679e-03 -3.7768795e-03 -8.5355258e-03\n",
      "  7.9550967e-03 -4.8430962e-03  8.4243221e-03  5.2609886e-03\n",
      " -6.5501807e-03  3.9575580e-03  5.4708594e-03 -7.4282014e-03\n",
      " -7.4055856e-03 -2.4756377e-03 -8.6252270e-03 -1.5801827e-03\n",
      " -4.0236043e-04  3.3001360e-03  1.4415972e-03 -8.8241365e-04\n",
      " -5.5940133e-03  1.7302597e-03 -8.9826871e-04  6.7939684e-03\n",
      "  3.9741215e-03  4.5290575e-03  1.4341431e-03 -2.6994087e-03\n",
      " -4.3666936e-03 -1.0321270e-03  1.4369689e-03 -2.6467817e-03\n",
      " -7.0735654e-03 -7.8056543e-03 -9.1217076e-03 -5.9348154e-03\n",
      " -1.8470082e-03 -4.3242811e-03 -6.4605214e-03 -3.7180765e-03\n",
      "  4.2892280e-03 -3.7388816e-03  8.3797537e-03  1.5337169e-03\n",
      " -7.2427099e-03  9.4338059e-03  7.6304432e-03  5.4950463e-03\n",
      " -6.8496312e-03  5.8225882e-03  4.0093577e-03  5.1861661e-03\n",
      "  4.2569390e-03  1.9407619e-03 -3.1710821e-03  8.3530620e-03\n",
      "  9.6114948e-03  3.7916750e-03 -2.8375010e-03  6.6632601e-06\n",
      "  1.2186278e-03 -8.4594022e-03 -8.2233679e-03 -2.3177716e-04\n",
      "  1.2370384e-03 -5.7435711e-03 -4.7256653e-03 -7.3463405e-03\n",
      "  8.3279097e-03  1.2112247e-04 -4.5090448e-03  5.7024667e-03\n",
      "  9.1806483e-03 -4.0998533e-03  7.9661217e-03  5.3769764e-03\n",
      "  5.8786790e-03  5.1239668e-04  8.2131373e-03 -7.0198057e-03]\n"
     ]
    }
   ],
   "source": [
    "# Sample sentences for training\n",
    "sentences = [\n",
    "    [\"i\", \"love\", \"machine\", \"learning\", \"by\", \"example\"],\n",
    "    [\"machine\", \"learning\", \"and\", \"deep\", \"learning\", \"are\", \"fascinating\"],\n",
    "    [\"word\", \"embedding\", \"is\", \"essential\", \"for\", \"many\", \"nlp\", \"tasks\"],\n",
    "    [\"word2vec\", \"produces\", \"word\", \"embeddings\"]\n",
    "]\n",
    "\n",
    "# Create and train Word2Vec model\n",
    "model = Word2Vec(sentences=sentences, vector_size=100, window=5, min_count=1, sg=0)\n",
    "\n",
    "# Access word vectors\n",
    "vector = model.wv[\"machine\"]\n",
    "print(\"Vector for 'machine':\", vector)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5a970f8a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embedded Data:\n",
      " tensor([[[-0.3944,  0.8023, -0.0500],\n",
      "         [-1.9144, -1.3619, -1.4696],\n",
      "         [-0.2408, -0.1748, -0.1506],\n",
      "         [ 0.8162, -0.7899,  0.3673]],\n",
      "\n",
      "        [[-0.3459, -2.2255,  0.1240],\n",
      "         [-0.3944,  0.8023, -0.0500],\n",
      "         [ 0.1515,  0.0214, -0.6475],\n",
      "         [-0.2408, -0.1748, -0.1506]]], grad_fn=<EmbeddingBackward0>)\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "# Sample data\n",
    "input_data = torch.LongTensor([[1, 2, 3, 4], [5, 1, 6, 3]])\n",
    "\n",
    "# Define the embedding layer\n",
    "vocab_size = 10  # Total number of unique words\n",
    "embedding_dim = 3  # Dimensionality of the embeddings\n",
    "embedding_layer = nn.Embedding(vocab_size, embedding_dim)\n",
    "\n",
    "# Pass input data through the embedding layer\n",
    "embedded_data = embedding_layer(input_data)\n",
    "\n",
    "# Print the embedded data\n",
    "print(\"Embedded Data:\\n\", embedded_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4535b2b0",
   "metadata": {},
   "source": [
    "# Best practices in the deployment and monitoring stage "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ac0af87",
   "metadata": {},
   "source": [
    "# Best practice 19 – Saving, loading, and reusing models "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8094ceed",
   "metadata": {},
   "source": [
    "### Saving and restoring models using pickle "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a6050317",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import datasets\n",
    "dataset = datasets.load_diabetes()\n",
    "X, y = dataset.data, dataset.target\n",
    "\n",
    "num_new = 30    # the last 30 samples as new data set\n",
    "X_train = X[:-num_new, :]\n",
    "y_train = y[:-num_new]\n",
    "X_new = X[-num_new:, :]\n",
    "y_new = y[-num_new:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e1589344",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>StandardScaler()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">StandardScaler</label><div class=\"sk-toggleable__content\"><pre>StandardScaler()</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "StandardScaler()"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Data pre-processing\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "de69a0b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "# Save the scaler\n",
    "pickle.dump(scaler, open(\"scaler.p\", \"wb\" ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "834b8d7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_scaled_train = scaler.transform(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3fdad9af",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-2 {color: black;background-color: white;}#sk-container-id-2 pre{padding: 0;}#sk-container-id-2 div.sk-toggleable {background-color: white;}#sk-container-id-2 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-2 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-2 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-2 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-2 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-2 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-2 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-2 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-2 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-2 div.sk-item {position: relative;z-index: 1;}#sk-container-id-2 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-2 div.sk-item::before, #sk-container-id-2 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-2 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-2 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-2 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-2 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-2 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-2 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-2 div.sk-label-container {text-align: center;}#sk-container-id-2 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-2 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>SVR(C=20)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" checked><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">SVR</label><div class=\"sk-toggleable__content\"><pre>SVR(C=20)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "SVR(C=20)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Regression model training\n",
    "from sklearn.svm import SVR\n",
    "regressor = SVR(C=20)\n",
    "regressor.fit(X_scaled_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2b81cd7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the regressor\n",
    "pickle.dump(regressor, open(\"regressor.p\", \"wb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6e949d68",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Deployment\n",
    "my_scaler = pickle.load(open(\"scaler.p\", \"rb\" ))\n",
    "my_regressor = pickle.load(open(\"regressor.p\", \"rb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3fc72c06",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_scaled_new = my_scaler.transform(X_new)\n",
    "predictions = my_regressor.predict(X_scaled_new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d205b741",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Health check on the model, R^2: 0.613\n"
     ]
    }
   ],
   "source": [
    "# Monitor\n",
    "from sklearn.metrics import r2_score\n",
    "print(f'Health check on the model, R^2: {r2_score(y_new, predictions):.3f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "123c1797",
   "metadata": {},
   "source": [
    "### Saving and restoring models in TensorFlow "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0bbff6f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "\n",
    "cancer_data = datasets.load_breast_cancer()\n",
    "X = cancer_data.data\n",
    "X = scaler.fit_transform(X)\n",
    "y = cancer_data.target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c0f7971b",
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 0.005\n",
    "n_iter = 10\n",
    "\n",
    "tf.random.set_seed(42)\n",
    "\n",
    "model = keras.Sequential([\n",
    "    keras.layers.Dense(units=1, activation='sigmoid')\n",
    "])\n",
    "\n",
    "model.compile(loss='binary_crossentropy',\n",
    "              optimizer=tf.keras.optimizers.Adam(learning_rate))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b4b5e9da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "18/18 [==============================] - 1s 1ms/step - loss: 0.4570\n",
      "Epoch 2/10\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.2958\n",
      "Epoch 3/10\n",
      "18/18 [==============================] - 0s 826us/step - loss: 0.2210\n",
      "Epoch 4/10\n",
      "18/18 [==============================] - 0s 884us/step - loss: 0.1817\n",
      "Epoch 5/10\n",
      "18/18 [==============================] - 0s 854us/step - loss: 0.1572\n",
      "Epoch 6/10\n",
      "18/18 [==============================] - 0s 884us/step - loss: 0.1408\n",
      "Epoch 7/10\n",
      "18/18 [==============================] - 0s 884us/step - loss: 0.1296\n",
      "Epoch 8/10\n",
      "18/18 [==============================] - 0s 884us/step - loss: 0.1203\n",
      "Epoch 9/10\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.1130\n",
      "Epoch 10/10\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.1075\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x2b76a2dff70>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X, y, epochs=n_iter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d768c389",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense (Dense)               (None, 1)                 31        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 31\n",
      "Trainable params: 31\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ff4d6877",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./model_tf\\assets\n"
     ]
    }
   ],
   "source": [
    "path = './model_tf'\n",
    "model.save(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "2e36664c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense (Dense)               (None, 1)                 31        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 31\n",
      "Trainable params: 31\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "new_model = tf.keras.models.load_model(path)\n",
    "\n",
    "new_model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c89b149",
   "metadata": {},
   "source": [
    "### Saving and restoring models in PyTorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "71b3da5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_torch = torch.FloatTensor(X)\n",
    "y_torch = torch.FloatTensor(y.reshape(y.shape[0], 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "cb492636",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(42)\n",
    " \n",
    "model = nn.Sequential(nn.Linear(X.shape[1], 1),\n",
    "                      nn.Sigmoid())\n",
    " \n",
    "loss_function = nn.BCELoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "92cc7fb6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 - loss: 0.8387020826339722\n",
      "Epoch 1 - loss: 0.7999904751777649\n",
      "Epoch 2 - loss: 0.76298588514328\n",
      "Epoch 3 - loss: 0.7277476787567139\n",
      "Epoch 4 - loss: 0.6943162679672241\n",
      "Epoch 5 - loss: 0.6627081036567688\n",
      "Epoch 6 - loss: 0.6329135298728943\n",
      "Epoch 7 - loss: 0.6048969030380249\n",
      "Epoch 8 - loss: 0.5786024332046509\n",
      "Epoch 9 - loss: 0.5539639592170715\n"
     ]
    }
   ],
   "source": [
    "def train_step(model, X_train, y_train, loss_function, optimizer):\n",
    "    pred_train = model(X_train)\n",
    "    loss = loss_function(pred_train, y_train)\n",
    "    model.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    return loss.item()\n",
    "\n",
    "\n",
    "for epoch in range(n_iter):\n",
    "    loss = train_step(model, X_torch, y_torch, loss_function, optimizer)\n",
    "    print(f\"Epoch {epoch} - loss: {loss}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "1d5f616b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sequential(\n",
      "  (0): Linear(in_features=30, out_features=1, bias=True)\n",
      "  (1): Sigmoid()\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "cf6f829f",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = './model.pth'\n",
    "torch.save(model, path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "08226868",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sequential(\n",
      "  (0): Linear(in_features=30, out_features=1, bias=True)\n",
      "  (1): Sigmoid()\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "new_model = torch.load(path)\n",
    "print(new_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f57a1114",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05c10538",
   "metadata": {},
   "source": [
    "Readers may ignore the next cell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "98a92cbf",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NbConvertApp] Converting notebook ch10_part2.ipynb to python\n",
      "[NbConvertApp] Writing 4152 bytes to ch10_part2.py\n"
     ]
    }
   ],
   "source": [
    "!jupyter nbconvert --to python ch10_part2.ipynb --TemplateExporter.exclude_input_prompt=True"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
